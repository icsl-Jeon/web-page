import YouTube, { YouTubeProps } from "react-youtube";
import Image from "next/image";

# Gentle introduction to Hybrid A\* in minutes

<div className="sm:px-5 my-10 flex flex-col">
  <YouTube videoId="qXZt-B7iUyw" className="videoWrapper" />
  <b>Hybrid A* algorithm video</b>
</div>

[Hybrid A\*](https://journals.sagepub.com/doi/abs/10.1177/0278364909359210) is
considered one of the most popular path planning algorithms for car-like robots.
It was developed by
[Dmitri Dolgov](https://en.wikipedia.org/wiki/Dmitri_Dolgov), who currently
serves as the co-chief executive officer of Waymo, Google's self-driving car
project.

Academically, Hybrid A\* has garnered more than 1000 citations, after
demonstrating its exceptional performance in the
[DARPA challenge](<https://en.wikipedia.org/wiki/DARPA_Grand_Challenge_(2007)>).
Even as of 2023, this method remains one of the frequently used frontend
algorithms for car motion planning (e.g., papers of
[Bai Li](https://ieeexplore.ieee.org/abstract/document/9531561/)
or[Zhang](https://s3-us-west-2.amazonaws.com/ieeeshutpages/xplore/xplore-shut-page.html)).

When I initially read this paper, it was not that easy to follow, as I had to
expand from grid domains. This article was written to help you understand the
principles, parameter tuning, with some pros and cons.

By the way, source implementations can be found from various platform such as

- [KTH thesis (ROS1)](https://github.com/karlkurzer/path_planner) (I personally
  digged into this version).

- [nav2 (ROS2)](https://navigation.ros.org/configuration/packages/configuring-smac-planner.html)

- [Unity](https://github.com/Habrador/Self-driving-vehicle)
- [Python](https://github.com/zhm-real/MotionPlanning)

## First of all, Djkstra and A\*

In order to understand Hybrid*, you first recap the serach algorithms
[Djikstra algorithm](https://en.wikipedia.org/wiki/Dijkstra%27s_algorithm) and
[A* algorithm](https://en.wikipedia.org/wiki/A*_search_algorithm).

### 1. Djikstra

The correct way to understand Djikstra algorithm is seeing it as "propagating"
computation to find the
[shortest path tree](https://en.wikipedia.org/wiki/Shortest-path_tree). The
purpose of the algorithm is not to find a shortest path to a single goal! It
find for all of the possible nodes.

<div className="flex flex-col items-center">
  <Image
    src={"/images/post19/djikstra-algorithm.gif"}
    width={600}
    height={500}
    className="mx-auto"
  />
  <b>Borrowed from [zhm-real](https://github.com/zhm-real/PathPlanning) </b>
</div>

In the above animation, the gray circle notes that we computed the shortest path
from the start(blue dot) to the cell (a.k.a., node). The reason why it looks
like a path finding is that, the implementation terminated the propagation when
it hits the goal.

Thus, the search does nothing to do with the single goal.

### 2. A\*

What the most robot researchers do for all days to find a route to a "single"
goal (although the goal can be changed). To this end, the
[robot researchers](https://en.wikipedia.org/wiki/Shakey_the_robot) tried to
modify the Djikstra algorithm to make it propagate toward a single goal.

<div className="flex flex-col items-center">
  <Image
    src={"/images/post19/a-star-algorithm.gif"}
    width={600}
    height={500}
    className="mx-auto"
  />
  <b>Borrowed from [zhm-real](https://github.com/zhm-real/PathPlanning) </b>
</div>

To guide the search, we propagate towards the node that is "expected" to be the
best direction based on two terms:

- **Cost-so-far (already determined)**: Has this cell accumulated a lower cost
  until it reached this point from the start?
- **Cost-to-goal (we do know know exactly)**: How optimistic is the estimation
  of this cell's goodness towards reaching the goal?

The first term is often denoted as $g(x)$ and the latter as $h(x)$. We call the
latter as a _heuristic_. We search the next $x_{next}$ in a greedy manner: the
lowest $g(x_{next}) + h(x_{next})$ inside the search queue.

#### Admissibility of heuristic function

Since we perform a guided search relying on $h(x)$, this function must be
thoughtfully designed. For you to find the global optimal, an essential
condition for the heuristic is that: **it should output the expected cost to
goal as optimistically as possible**. In the case of using A\* in a grid, this
function is typically chosen as the Euclidean distance from \(x\) to the goal.

The reason for this choice is to ensure that we do not miss the opportunity to
discover the best possible solution, that is, the global optimum. If this
function does not promise this condition, there is no guarantee that A* is *
(notation for global optimum).

### 3. Reflecting kinematics: Hybrid A\*

A\* algorithm works well in grid domain with many applications including
[computer games](https://www.youtube.com/watch?v=uiUQ14C1O9Q). But this guided
search on a grid has limitation when we try to apply for
[non holonomic systems](https://en.wikipedia.org/wiki/Nonholonomic_system) such
as car. Although the output of A\* can be globally optimal in the grid,
resultant path can be inefficient when it was actually tracked by the dynamics.

<div className="flex flex-col items-center">
  <Image
    src={"/images/post19/a-star-not-possible.png"}
    width={300}
    height={300}
    className="mx-auto"
  />
  <b>
    Borrowed from [Karl's master
    thesis](https://kth.diva-portal.org/smash/get/diva2:1057261/FULLTEXT01.pdf){" "}
  </b>
</div>

In the above example, even though the blue straight line is the global optimal
to reach $x_{g}$, the path cannot be tracked exactly due to initial heading of
the car. That is, the output of A\* might not be useful.
[The original paper](https://journals.sagepub.com/doi/abs/10.1177/0278364909359210)
tried to tacked this: **how can we consider kinematics of the car while guiding
the path search like A\*?**

## Hybrid A\* explained

From this section, we start to discuss hybrid A\*. I will base my explanation on
the original paper by Dimitri.

### 1. Objective

The conventional A\* tries to find the shortest path from a position
$x_0 \in R^2$ to goal position $x_f\in R^2$ (or course we can use in
three-dimension. But for simplicity, we confine to 2-dimension). But this time,
hybrid A\* will effort to find a sequence of safe poses from
$s_0 = (x_0, \theta_0) \in SE(2)$ to $s_0 = (x_f, \theta_f) \in SE(2)$,
minimizing the travel length. Thus, our domain for searched elements is $SE(2)$.

#### Kinematic models

In the paper, the model is assumed to be car-like moving as the below:

<div className="flex flex-col items-center">
  <Image
    src={"/images/post19/kinematics.png"}
    width={600}
    height={300}
    className="mx-auto"
  />
</div>
In the paper, the expansion to the next step $n+1$ follow one of the three: two maximum
curvatures (left / right) and straight line. Thus, the shortest movement between
any two states $s_a$ and $s_b$ can be analytically computed with [Dubins path](https://en.wikipedia.org/wiki/Dubins_path).

This model can be extended to have reverse motions, giving us six possible
expansions. In this case, any two states can be connected with shortest path
following
[Reeds Shepp](https://atsushisakai.github.io/PythonRobotics/modules/path_planning/reeds_shepp_path/reeds_shepp_path.html).

Of course, you can extend the expansion model to suit your scenario such as
[this paper](https://journals.sagepub.com/doi/full/10.1177/1729881421992958).

### 2. Expansion (opening)

When a state $x_n \in R^2$ is propagated in A* grid field, we opened the
neighboring cells, which is equal to moving along the grid. Also, the states
corresponds to the center of each cell. These become different in hybrid A*.

#### Opening cells

<div className="flex flex-col items-center">
  <Image
    src={"/images/post19/expansion.png"}
    width={600}
    height={300}
    className="mx-auto"
  />
</div>
In hybrid A\*, a propagation of state 
$s_n = (x_n, {\theta}_n)$ opens new cells by simulating the kinematics as the above figure shows.
Thus, the new state $s_{n+1} = (x_{n+1}, {\theta}_{n+1})$ can hardly arrive the center of the cells.  
(I tried to show this with the white circles).

#### Cost-so-far $g(s)$

Computing the costs of each state $s_{n+1}$ is relatively similar. We determine
the cost by considering the length of the arc between $s_n$ and $s_{n+1}$. The
difference lies in our ability to penalize less desirable movements. For
instance, in the above picture, we can impose a higher penalty on turning
movements ($s_{n+1}^2$ and $s_{n+1}^3$) compared to the straight movement
$s_{n+1}^1$). Furthermore, when we utilize reverse movements for expansion, the
reverse movement will also incur a higher penalty.

#### Pruning

At this point, you will be confused: what if more than two states share a same
cell? What is the meaning of cells then? Here pruning comes in.

<div className="flex flex-col items-center">
  <Image
    src={"/images/post19/pruning.png"}
    width={500}
    height={300}
    className="mx-auto"
  />
</div>

For the performance reasons, we remove the states if another state in the same
cell has attained a less cost-so-far. In the above picture, assuming turning
movement will penalized more, the red circle will be pruned as it went through
two turning movements.

### 3. Heuristic $h(s)$

From the above section, I explained how to expand and open new cells from a
state $s_{n}$. As in the original A\*, we should choose the best state $s_{n}$
to propagate at the current iteration, based on the heuristic plus cost-so-far.

#### Nonholonomic heuristic

As we discussed [here](#admissibility-of-heuristic-function), a heuristic should
be best optimistic to be admissible. The concept of heuristic is similar to grid
A\*: **the expected shortest path to goal**. But here of course, the goal is in
$SE(2)$ not a positional domain.

As I told [here](#kinematic-models), arriving to a pose from a pose with the
kinematic can be achieved by Dubins path or Reeds Shepp path. Can we use this
then? Although it is admissible, we can be more accurately estimate the
remaining distance by considering obstacles. Take a look at the wonderful
picture by
[Karl](https://kth.diva-portal.org/smash/record.jsf?pid=diva2%3A1057261&dswid=-5165).

<div className="flex flex-col items-center">
  <Image
    src={"/images/post19/hueristic.png"}
    width={700}
    height={300}
    className="mx-auto my-5"
  />
</div>
In the (c) of the picture, we can overestimate the future cost. This can waste our
propagation into a wrong direction (in this case, toward the deep in the wall..).
We can help this by computing the shortest path in positional domain as (d) shows.

#### Holonomic heuristic considering obstacles

How can we know the shortest path in a grid manner then? The original authors do
not talk much details except a kind of _dynamic programming_. I found this part
diverged depending on the implementation. From example, Smac planner of nav2
used dynamic programming similar to dijkstra. But it propagate shortest distance
starting from the goal not from the start. See more details
[here](https://github.com/ros-planning/navigation2/blob/96673e216705fe837e5c53ce6a8469f204da5262/nav2_smac_planner/src/node_hybrid.cpp#L433).
Karl's
[implementation](https://github.com/karlkurzer/path_planner/blob/887996746c275e2c8335ae77ea096969079e688f/src/algorithm.cpp#L442)
runs A star until the goal position.

In either way, we need to operate on 2D grid when it comes to obstacle
heuristic, and some
[down-sampling resolution](https://github.com/ros-planning/navigation2/tree/main/nav2_smac_planner#costmap-resolutions)
seems unavoidable to reduce computation.

#### Heuristic of hybrid A\*

We take the maximum of the two heuristics as our final heuristic $h(s)$. We
choose the best state $s_{next}$ with minimum value of $g(s) + h(s)$ for the
next [expansion](#2-expansion-opening). Choosing the best is automatically
handled by popping
[priority queue](https://en.wikipedia.org/wiki/Priority_queue) If you are not
familiar with this data structure, I highly recommend to study it. This is a
must-know concept to implement your A\* algorithms.

### 4. Analytical expansion (a.k.a., shot to goal)

This process is a crucial and distinctive aspect that significantly impacts the
final result.

## Analysis

### Optimality

### Performance

## Future application
